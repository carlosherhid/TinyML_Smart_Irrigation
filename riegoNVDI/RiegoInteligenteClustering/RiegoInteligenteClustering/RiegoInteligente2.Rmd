---
title: "Riego Inteligente Parte II: Clustering y regresión"
author: "Paula Susana Gómez Bernal"
date: "25/1/2022"
output:
  html_document:
    df_print: paged
    highlight: kate
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_float: yes
    toc_depth: 4
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(cache = TRUE)
```



# Configuración

```{r}
source(file.path("code","include.R"), encoding = "UTF-8")
dirs$data <- "datosTFG"
dflt$ini <- as.Date("2019-01-01")
dflt$fin <- as.Date("2021-05-17")
```

```{r}
sum.period <- function(...) {
  v <- c(...)
  lubridate::seconds_to_period(sum(lubridate::period_to_seconds(v)))
}
```



# Tarea 5.1. Primeros modelos y resultados (`ML.R`)

## Valores por defecto

> **¡IMPORTANTE!** Modelo de regresión por defecto: `dflt$model`.
Otros modelos de regresión: `dflt$models`.
[Otros modelos disponibles](https://topepo.github.io/caret/available-models.html).

```{r}
dflt$models
dflt$model
```

## Procesamiento

> La función que hay que llamar para probar los escenarios 1 (un modelo para todos los contratos) y 2 (un modelo para cada contrato) es `ML$initResultsNone()`.
Ésta se apoya en `ML$probarModelo()` y en `ML$promediarResults()`.

Como siempre, tenemos los parámetros `ind(s)`, `mask(s)`, `agg(s)`, `crop(s)`, `int(s)` para indicar el conjunto de datos sobre el que probar los modelos `model(s)`.
Naturalmente, solo se puede probar para los contratos que tienen dicho conjunto de datos.

`ML$promediarResults()` simplemente saca la media de los resultados del escenario 2 y suma los tiempos de ejecución para obtener el tiempo total.

> La función principal encargada de obtener los resultados y guardarlos en un fichero especial para evitar repetir las mismas pruebas (esto será cuando usemos clustering) es `ML$probarModelo()`, **que está paralelizada**.

Esta función, dado uno o varios contratos,

- lee sus datos (`DatInt$readDatInt()`),
- los particiona **aleatoriamente** en train y test (`ML$particionarDatos()`),

- los preprocesa/**normaliza** aplicando **opcionalmente PCA** (`ML$preprocesarDatos()`),
- entrena varios modelos con los datos de train optimizando los parámetros de ajuste (`ML$entrenarModelo()`),
- y evalúa el modelo final sobre los datos de test (`ML$testearModelo()`).

> **¡IMPORTANTE!** Hay que tener en cuenta,
>
> - que el particionamiento se realiza para cada contrato y después se juntan los distintos train/test.
> - Se puede no aplicar PCA, i.e., PCA=0 (`byPCA=0L`) o probar todas las posibilidades, i.e., PCA=0,1,2...,#predicctores (`byPCA=1L`).
> - Para optimizar los parámetros se usa 10-fold CV con 10 repeticiones (`control=ML$control`).
> - `caret` prueba con unos parámetros por defecto, que puede que no sean los adecuados  dependiendo de la cantidad de observaciones disponibles llevando a errores (como pasa en el escenario 2) o sobreajuste.
Para estudiar esto se puede también evaluar el modelo final sobre los datos de train (`extended=T`).
> - **Si se usa un modelo específico de prediccion de series (como LSTM), muchos de los pasos deberían cambiar (ver última sección)**.

```{r eval=FALSE}
# No ejecutar (tarda más de 3d)
ML$initResultsNone(inds = dflt$ind, masks = unique(c(NA,dflt$mask)),
                   aggs = dflt$agg, crops = dflt$crop, ints = dflt$ints,
                   models = dflt$models[5:6], byPCA = 1L, control = ML$control)
```

> `gbm` y `svmRadial` tienen un tiempo de ejecución aceptable. `rf` tarda muuucho tiempo...

## Leyendo los ficheros

Para leer el fichero especial donde `ML$probarModelo()` guarda los resultados de un conjunto de datos y un modelo:

```{r}
str(ML$leerResults())
```

- `Group` guarda los contratos separados por `_`.
- `N` indica el número de contratos que hay en `Group`.
- `PCA`
- `MAE`, `MAPE`, `MSE`, `RMSE`, `CVRMSE`
- `CV` es la media de las observaciones de  test, el cociente de `CVRMSE=RMSE/CV`.
- `user`, `system`, `elapsed`

Para leer los resultados de un conjunto de datos y un modelo para los escenarios 1 y 2:

```{r}
str(ML$leerResultsNone())
```

- `n` es el número de clusters/modelos/filas de la tabla `ML$leerResults()` de los cuáles se ha promediado sus resultados y sumado sus tiempos de ejecución.

Para leer los resultados de varios conjuntos de datos y varios modelos para los escenarios 1 y 2:

```{r}
str(res_None <- ML$readResultsNone())
res_None %<>%
  dplyr::select(!c(CV,user,system)) %>%
  dplyr::rename(Time = elapsed) %>%
  dplyr::mutate_at("Time", lubridate::seconds_to_period) %>%
  dplyr::mutate_if(is.numeric, round, 4)
summary(res_None %>% dplyr::mutate_if(is.character, factor))
```

## Algunas observaciones

Podemos separar los resulatdos de los distintos escenarios:

```{r}
res_None %<>% dplyr::select(!c(Ind, Agg, Crop)) %>%
  dplyr::mutate(Scenario = ifelse(n == 1L, 1L, 2L), .before = n)
res_todos <- res_None %>% dplyr::filter(Scenario == 1L)
res_cada1 <- res_None %>% dplyr::filter(Scenario == 2L)
```

Podemos ver que **la serie NDVI con nubes (`Mask==NA`) es mucho más difícil de predecir**, y que **los mejores resultados se obtienen sin PCA (`PCA==0L`)**:

```{r}
res_todos %>% dplyr::group_by(Model, Int, Mask) %>%
  dplyr::slice_min(CVRMSE) %>% dplyr::ungroup() %>%
  dplyr::select(!c(MAE,MAPE,MSE,RMSE))
```

Se observa que a mayor cantidad de predictores (mayor `PCA` o `PCA==0L`) los resultados son mejores, pero si tomamos las series agregadas (`Int="agg"`) con sólo 4 predictores obtenemos muy buenos resultados (mejor que `Int=="redim"` y `PCA<14`):

```{r}
res_todos %>% dplyr::group_by(Model, Mask) %>%
  dplyr::slice_min(CVRMSE, n = 5L) %>% dplyr::ungroup() %>%
  dplyr::select(!c(MAE,MAPE,MSE,RMSE))
```

Podemos usar las series agregadas si nuestro objetivo simplemente es predecir el NDVI,
sin preocuparnos de cómo influye el riego de cada día.
La cantidad de predictores tiene mucho que ver con el tiempo de ejecución de RF, que es bastante elevado como podemos ver...

```{r}
# Tiempo total de ML$initResultsNone(...)
# sum.period(res_None$Time)
res_None %>% dplyr::group_by(Model) %>% dplyr::summarise_at("Time", sum.period)
```
```{r}
# Solo lo que nos interesa, sin PCA: byPCA=0L, mask="scl_7_8_9", int="redim"
# sum.period(dplyr::filter(res_None, PCA == 0L, Mask == "scl_7_8_9", Int == "redim")$Time)
res_None %>% dplyr::filter(PCA == 0L, Mask == "scl_7_8_9", Int == "redim") %>%
  dplyr::group_by(Model) %>% dplyr::summarise_at("Time", sum.period)
```

Del escenario 2 es más complicado extraer conclusiones ya que **muchos parques no tienen suficientes observaciones para entrenar los modelos con los hiperparámetros que prueba `caret` por defecto**.

```{r}
res_cada1 %>% dplyr::group_by(Model, Int, Mask) %>%
  dplyr::slice_min(CVRMSE) %>% dplyr::ungroup() %>%
  dplyr::select(!c(MAE,MAPE,MSE,RMSE))
```

```{r}
res_cada1 %>% dplyr::group_by(Model, Mask) %>%
  dplyr::slice_min(CVRMSE, n = 5L) %>% dplyr::ungroup() %>%
  dplyr::select(!c(MAE,MAPE,MSE,RMSE))
```

## Guardando

Nos quedamos con los resultados sin PCA (`PCA == 0L`) para la serie NDVI sin nubes (`Mask == "scl_7_8_9"`) y las series diarias redimensionadas (`Int == "redim"`) y los guardamos:

```{r}
(res_cada1 %<>%
    dplyr::filter(Mask == "scl_7_8_9", Int == "redim", PCA == 0L) %>%
    dplyr::select(!c(Mask,Int,PCA)))
escribirTablaLatex(res_todos, "res2", F)
```

```{r}
(res_todos %<>%
    dplyr::filter(Mask == "scl_7_8_9", Int == "redim", PCA == 0L) %>%
    dplyr::select(!c(Mask,Int,PCA)))
escribirTablaLatex(res_todos, "res1", F)
```

```{r}
dplyr::bind_rows(res_todos, res_cada1) %>%
  escribirTablaLatex("res12", F)
```



# Tarea 4. Clustering de parques (`Clust.R`)

## Valores por defecto

> **¡IMPORTANTE!** Paquetes de R para clustering de series temporales: `dflt$pkgs`.
El paquete `pdc` utiliza la métrica PD, mientras que `TSclust` permite elegirla de entre varias alternativas (una de ellas es precisante PD).
Algunas de las métricas tienen parámetros que hemos prefijado.
Cada combinacion métrica/parámetros posible tiene un identificador, que se guardan en `dflt$disss`.
>
> Las series que podemos usar para agrupar los parques (`dflt$series`) son:
>
> - La serie unidimensional de consumos diarios (`serie="Riego"`).
Ésta puede dar problemas para algunas métricas al ser constante 0 para algunos parques.
> - La serie unidimensional de imágenes de índices de verdor agregadas (`serie="Verdor"`).
Ésta es la recomendada y usada por defecto.
> - Los summaries de las imágenes de índices de verdor como series multidimensionales (`serie="VerdorMulti"`). Ésta sólamente podemos usarla con `pkg="pdc"`.

En cualquier caso, indicamos `ind, mask, agg` para determinar el conjunto de contratos para los que haremos el clustering, que serán aquellos para los que después probaremos los modelos, es decir, aquellos que tengan series de índices (y de consumo).

```{r}
dflt$serie
dflt$series
dflt$pkg
dflt$pkgs
dflt$diss
dflt$disss
```

## Procesamiento

> Para calcular y guardar los clusters se usa `Clust$initClusts()`, que se apoya en `Clust$calcularClust()`.

`Clust$calcularClust()`

- prepara las series de datos en el tipo de dato (matriz/data.frame) conforme las espera el paquete a usar (por filas/columnas) (`Clust$prepararDatos()`)
- obtiene el clustering (objeto tipo `clust`) y otros valores (`Clust$clust()`), entre los que destacamos una tabla con a qué cluster pertenece cada contrato para 2,3,...,#contratos/2 clústeres (generada con `stats::cutree()`), que es la que se guarda y se puede leer después (`Clust$leerClust()`).

Por otra parte, `Clust$clust()` obtiene el clustering dependiendo de si usamos `pdc` (`pdc::pdclust()`) o `TSclust` (`Clust$tsclust()`).

`Clust$tsclust()` funciona de manera análoga a `pdc::pdclust()`:

- primero calcula la matriz de distancias (`TSclust::diss()`, análoga a `pdc::pdcDist()`)
- y después obtiene el clustering jerárquico (`stats::hclust()`).

```{r eval=FALSE}
Clust$initClusts(series = dflt$series, pkgs = "pdc")
Clust$initClusts(series = dflt$serie, pkgs = "TSclust")
```

> Todos los clustering tardan poco tiempo en calcularse, menos `FRECHET` y `CORT.FRECHET` que pueden tardar 5-10 minutos.

## Leyendo los ficheros

Para leer la tabla con a qué cluster pertenece cada contrato para 2,3,...,#contratos/2:

```{r}
str(Clust$leerClust())
```

## Tarea 6.2. Visualización de datos (tablas e histogramas)

Sin embargo, si queremos dibujar un clustering (`Clust$plotClust()`), necesitamos un objeto `clust`, que es lo que devuelve `Clust$calcularClust()`, no `Clust$leerClust()`.

```{r}
system.time(clust <- Clust$calcularClust())
str(clust , max.level = 1L)
attr(clust , "param")
```


```{r}
subcjto = clust$grp.s$`3`[[2]] # segundo cluster para tres clusters
Clust$plotClust(clust, ts.as.lab = F)
Clust$plotClust(clust, subcjto, ts.as.lab = F)
Clust$plotClust(clust, subcjto, ts.as.lab = T)
Clust$plotClust(clust, k = 11L, ts.as.lab = T, f_save = png) # bmp, jpeg, tiff
```



# Tarea 5.2. Modelos para cada cluster (`Clust.R`)

## Procesamiento

> La función que hay que llamar para probar el escenario 3 (un modelo para cada grupo de contratos) es `Clust$initResultsClust()`.
Ésta se apoya en `Clust$probarClust()` y en `Clust$promediarResults()`.

`Clust$probarClust()` se apoya en `ML$probarModelo()`, haciendo **una llamada para cada cluster DISTINTO**. Ya que el clustering es jerárquico, cuando pasamos de, por ejemplo, 5 clusters a 6 clusters, todos los clusters son los mismos menos 1 que se divide en 2, por lo que sólo tenemos que entrenar 2 modelos, pues ya tenemos los resultados de los otros 4.
Recuerda que `ML$probarModelo()` guarda los resultados en un fichero aparte.
SOLO SE PRUEBA PARA PCA=0, es decir, SIN APLICAR PCA.

Para cada posible cantidad de clusters, `ML$promediarResults()` saca la media de los resultados de cada cluster, de modo que cada parque tenga el mismo peso. Puesto que guardamos los resultados por cluster y no por contrato (pero se entiende que todos los contratos del mismo cluster tienen el mismo resultado) esto es una media ponderada donde el peso de cada cluster es proporcional al número de parques que lo compone.
**Cuando no se pueden obtener resultados para alguno de los grupos**, se toman los resultados del primer grupo que lo contiene (para un número menor de clusters) y sí tiene resultados.
El cómputo total de tiempo de ejecución es más sencillo, pues simplemente es sumar los tiempos de ejecución de cada cluster.

```{r eval=FALSE}
# No ejecutar (tarda más de 3d)
Clust$initResultsClusts(series = dflt$series, pkgs = "pdc")
Clust$initResultsClusts(series = dflt$serie, pkgs = "TSclust")
```

## Leyendo los ficheros

Para leer los resultados de un conjunto de datos, un modelo y un clustering del escenario 3:

```{r}
str(Clust$leerResultsClust())
```

Para leer los resultados de un conjunto de datos, varios modelos y varios clustering del escenario 3:

```{r}
str(res_pdc <- Clust$readResultsClust(series = dflt$series, pkgs = "pdc",
                                      models = dflt$models[5:6]))
res_pdc %<>%
  dplyr::rename(Time = elapsed) %>%
  dplyr::mutate_at("Time", lubridate::seconds_to_period) %>%
  # dplyr::mutate_if(is.numeric, round, 4) %>%
  dplyr::select(!c(Pkg, Diss, PCA, CV, user, system))
summary(res_pdc %>% dplyr::mutate_if(is.character, factor))
```

```{r}
str(res_TSclust <- Clust$readResultsClust(series = dflt$serie, pkgs = "TSclust",
                                          disss = dflt$disss[-c(26,27,33)],
                                          models = dflt$models[5:6]))
res_TSclust %<>%
  dplyr::rename(Time = elapsed) %>%
  dplyr::mutate_at("Time", lubridate::seconds_to_period) %>%
  # dplyr::mutate_if(is.numeric, round, 4) %>%
  dplyr::select(!c(Pkg, Serie, PCA, CV, user, system))
summary(res_TSclust %>% dplyr::mutate_if(is.character, factor))
```

## Guardando

Nos quedamos con los mejores resultados para cada clustering y los guardamos:

```{r}
(best_pdc <- res_pdc %>% dplyr::group_by(Serie, Model) %>%
    dplyr::slice_min(CVRMSE) %>% dplyr::ungroup() %>%
    dplyr::mutate_if(is.numeric, round, 4)) %>%
  dplyr::select(!c(MAE,MAPE,MSE,RMSE))
# escribirTablaLatex(best_pdc, "pdc", F)
```

```{r}
(best_TSclust <- res_TSclust %>% dplyr::group_by(Diss, Model) %>%
    dplyr::slice_min(CVRMSE) %>% dplyr::ungroup() %>%
    dplyr::arrange(factor(Diss, levels = dflt$disss)) %>%
    dplyr::mutate_if(is.numeric, round, 4)) %>%
  dplyr::select(!c(MAE,MAPE,MSE,RMSE))
# escribirTablaLatex(best_TSclust, "TSclust", F)
best_TSclust_gbm <- best_TSclust %>%
  dplyr::filter(Model == "gbm") %>% dplyr::select(!Model)
escribirTablaLatex(best_TSclust_gbm, "gbm", F)
best_TSclust_rf  <- best_TSclust %>%
  dplyr::filter(Model == "rf") %>% dplyr::select(!Model)
escribirTablaLatex(best_TSclust_rf , "rf" , F)
```

## Algunas observaciones

```{r}
# como de mejores son los resultados obtenidos por rf frente a gbm
summary(best_TSclust_gbm$CVRMSE - best_TSclust_rf$CVRMSE)
# cuanto aumenta el tiempo de ejecucion de rf frente a gbm
summary(best_TSclust_rf$Time / best_TSclust_gbm$Time)
```

**El uso de `pdc` no mejora los resultados sin aplicar clustering**.

```{r}
best_pdc_vs_None <- dplyr::bind_rows(
  res_todos %>% dplyr::select(!Scenario) %>%
    dplyr::mutate(Serie = "None", .before = n),
  best_pdc)
best_pdc_vs_None %>% dplyr::arrange(Model, CVRMSE) %>%
  dplyr::select(!c(MAE,MAPE,MSE,RMSE))
```

**`TSclust` sí consigue alguna mejora para algunas métricas**:

- para `gbm` hay 21 métricas por encima de `Diss=="None"` y 11 por debajo,
- para `rf` hay 19 métricas por encima de `Diss=="None"` y 13 por debajo)

```{r}
best_TSclust_vs_None <- dplyr::bind_rows(
  res_todos %>% dplyr::select(!Scenario) %>%
    dplyr::mutate(Diss = "None", .before = n),
  best_TSclust)
best_TSclust_vs_None %>% dplyr::arrange(Model, CVRMSE) %>%
  dplyr::select(!c(MAE,MAPE,MSE,RMSE))
```

> Ojo con los tiempos!

Este es el tiempo que habríamos tardado si hubiéramos repetido casos:

```{r}
sum.period(res_pdc$Time, res_TSclust$Time)
# Solo TSclust
# sum.period(res_TSclust$Time)
res_TSclust %>% dplyr::group_by(Model) %>% dplyr::summarise_at("Time", sum.period)
# res_TSclust %>% dplyr::group_by(Model,Diss) %>% dplyr::summarise_at("Time", sum.period)
```

Y éste es el tiempo que hemos tardado realmente en la segunda tanda de pruebas:

```{r}
res <- list(gbm = ML$leerResults(model = "gbm", pca = 0L),
            rf = ML$leerResults(model = "rf", pca = 0L)) %>%
  listDF2DF("Model") %>%
  dplyr::rename(Time = elapsed) %>%
  dplyr::mutate_at("Time", lubridate::seconds_to_period) %>%
  dplyr::select(!c(PCA,CV,user,system))
# sum.period(res$Time)
contratos <- dflt$contratos("ConSeries", dflt$ind, dflt$mask, dflt$agg)
res %<>% dplyr::filter(!Group %in% contratos,
                       Group != paste0(contratos, collapse = "_"))
# sum.period(res$Time)
res %>% dplyr::group_by(Model) %>% dplyr::summarise_at("Time", sum.period)
```

## Tarea 6.2. Visualización de datos (tablas e histogramas)

```{r}
ply <- F
dflt$lan
lan = dflt$lan
carpeta = paths$saves(lan)
f_save <- "svg"
f_save <- "png"
# f_save <- NULL
```


```{r}
range(best_TSclust_vs_None$CVRMSE)
best_TSclust_vs_None$Diss %<>% factor(levels = unique(.))

ggplot2::ggplot(best_TSclust_vs_None, ggplot2::aes(Diss, CVRMSE, fill = Model)) +
  ggplot2::geom_col(position = "dodge") +
  ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(angle = 50)) +
  ggplot2::coord_cartesian(ylim = c(0.2,0.26)) +
  ggplot2::xlab("Clustering")

fichero <- paste0("clust_vs_CVRMSE",".",f_save)
msg("Guardando ",fichero)
ggplot2::ggsave(fichero, device = f_save, path = carpeta,
                width = 7, height = 5, units = "in")
```

Para ver la evolución del CVRMSE conforme varía el número de clusters para algunas de las métricas (las cuatro mejores, que coinciden para ambos modelos), añadimos el caso `n=1`, un clúster, es decir, sin aplicar clustering:

```{r}
head(res_TSclust_n_1 <- dplyr::bind_rows(
  tidyr::expand_grid(Diss = unique(res_TSclust$Diss),
                     res_todos %>% dplyr::select(!Scenario)),
  res_TSclust))
(best_diss_4_TSclust <- best_TSclust %>%
  dplyr::group_by(Model) %>% dplyr::slice_min(CVRMSE, n = 4) %>%
  dplyr::ungroup() %>% dplyr::select(Model, Diss))
res_4_TSclust_n_1 <- dplyr::semi_join(res_TSclust_n_1,
                                      best_diss_4_TSclust)
ggplot2::ggplot(res_4_TSclust_n_1, ggplot2::aes(n, CVRMSE, colour = Diss)) +
  ggplot2::geom_point(size = 0.5) + ggplot2::geom_line(size = 0.1) +
  ggplot2::facet_wrap(ggplot2::vars(Model))

fichero <- paste0("n_vs_CVRMSE",".",f_save)
msg("Guardando ",fichero)
ggplot2::ggsave(fichero, device = f_save, path = carpeta,
                width = 7, height = 5, units = "in")
```

> **¡IMPORTANTE!** No hay ninguna función que genere estos gráficos, pero sería lo recomendable para incluirlos en el dashboard. Mejor que de aquí, mirar el código de la última parte de `savesTFG.R` (para `lan = "sp"`) o de `savesPaper.R` (para `lan = "en"`).



# Para continuar... (`lstm.R`)

Los modelos de `caret` son listas de funciones y metadatos, lo cual nos permite
[definir nuestro propio modelo](https://topepo.github.io/caret/using-your-own-model-in-train.html),
como LSTM.

`lstm.R` tiene un boceto (nunca llegué a probarlo y comprobar que funciona correctamente).
Además, hay que tener en cuenta que este modelo aprende de observaciones pasadas, por lo que:

- no se pueden juntar observaciones de distintos parques así como así, una detras de otras...
- el particionamiento no puede ser aleatorio, sino que las primeras observaciones son train y las últimas son test (`ML$particionarDatos(random = F)`);
- lo mismo ocurre con el tunning de los parámetros... hay que cambiar el `control` (ver `ML$entrenarModelo()`).

Además, los datos no se normalizan, sino que se escalan al rango [-1,1] / [0,1] (`ML$preprocesarDatos(b = c(-1,1))`).


